<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Real-time Transcription</title>
  </head>
  <body>
    <h1>Real-time Transcription</h1>
    <button id="startButton">Start Recording</button>
    <button id="stopButton" disabled>Stop Recording</button>
    <button id="interruptButton" disabled>Interrupt</button>
    <div id="transcript"></div>

    <script>
      const startButton = document.getElementById("startButton");
      const stopButton = document.getElementById("stopButton");
      const interruptButton = document.getElementById("interruptButton");
      const transcriptDiv = document.getElementById("transcript");
      let mediaRecorder;
      let audioChunks = [];
      let audioContext;
      let sourceNode;
      let audioQueue = [];
      let isPlaying = false;
      let socket;

      // Initialize WebSocket connection
      function initWebSocket() {
        socket = new WebSocket("ws://localhost:8080/voice"); // Replace with your server URL

        socket.onopen = () => {
          console.log("WebSocket connection established");
        };

        socket.onmessage = (event) => {
          if (event.data instanceof Blob) {
            event.data.arrayBuffer().then((arrayBuffer) => {
              console.log("Received audio data");
              audioQueue.push(arrayBuffer);
              if (!isPlaying) {
                playNextInQueue();
              }
              interruptButton.disabled = false;
            });
          } else {
            const message = JSON.parse(event.data);
            if (message.type === "stream_interrupted") {
              console.log("stream_interrupted");
              stopCurrentAudio();
            }
          }
        };

        socket.onclose = () => {
          console.log("WebSocket connection closed");
        };
      }

      initWebSocket();

      startButton.addEventListener("click", startRecording);
      stopButton.addEventListener("click", stopRecording);
      interruptButton.addEventListener("click", stopCurrentAudio);

      function startRecording() {
        stopCurrentAudio();

        navigator.mediaDevices
          .getUserMedia({ audio: true })
          .then((stream) => {
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = (event) => {
              // Create a FileReader to read the Blob data
              const reader = new FileReader();

              reader.onloadend = () => {
                // The result attribute contains the data as a base64 encoded string
                const base64data = reader.result.split(",")[1];

                const payload = JSON.stringify({
                  event: "media",
                  streamSid: "streamSid",
                  media: {
                    payload: base64data,
                  },
                });
                socket.send(payload);
              };

              // Read the Blob data as a data URL (which is base64 encoded)
              reader.readAsDataURL(event.data);
            };
            mediaRecorder.start(250);
            startButton.disabled = true;
            stopButton.disabled = false;
            interruptButton.disabled = true;
          })
          .catch((error) =>
            console.error("Error accessing microphone:", error)
          );
      }

      function stopRecording() {
        if (mediaRecorder && mediaRecorder.state !== "inactive") {
          mediaRecorder.stop();
          startButton.disabled = false;
          stopButton.disabled = true;
        }
      }

      function stopCurrentAudio() {
        if (sourceNode) {
          sourceNode.stop();
          sourceNode.disconnect();
          sourceNode = null;
        }
        audioQueue = [];
        isPlaying = false;
        interruptButton.disabled = true;
      }

      async function playNextInQueue() {
        if (audioQueue.length === 0) {
          isPlaying = false;
          interruptButton.disabled = true;
          return;
        }

        isPlaying = true;
        interruptButton.disabled = false;

        const arrayBuffer = audioQueue.shift();

        if (!audioContext) {
          audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();
        }

        try {
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          sourceNode = audioContext.createBufferSource();
          sourceNode.buffer = audioBuffer;
          sourceNode.connect(audioContext.destination);
          sourceNode.onended = playNextInQueue;
          sourceNode.start();
        } catch (error) {
          console.error("Error decoding audio data:", error);
          playNextInQueue();
        }
      }

      // Ensure audio context is resumed on user interaction
      document.body.addEventListener(
        "click",
        () => {
          if (audioContext && audioContext.state === "suspended") {
            audioContext.resume();
          }
        },
        { once: true }
      );
    </script>
  </body>
</html>
